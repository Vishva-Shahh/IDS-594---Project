{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"IDS 594 Flask.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNOzOi8n1H4KRyW3LrdKeD1"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"gXqYdYkQfa4S","executionInfo":{"status":"ok","timestamp":1602446525542,"user_tz":300,"elapsed":49051,"user":{"displayName":"Vishva Vipin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gin93jSJ_DOfVuwBQIXZQmHlpLnLxatAOmK-YTeiw=s64","userId":"02934471236859300555"}},"outputId":"5216357a-bcdc-4f0b-8232-87e888e6cc45","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# import os\n","# os.listdir('../input/')\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"shxl9bW6mhQR","executionInfo":{"status":"ok","timestamp":1602446526009,"user_tz":300,"elapsed":49496,"user":{"displayName":"Vishva Vipin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gin93jSJ_DOfVuwBQIXZQmHlpLnLxatAOmK-YTeiw=s64","userId":"02934471236859300555"}}},"source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","import os\n","os.chdir('/content/drive/My Drive/IDS 576/Project/Final Project (1)')"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"N6n8D1Wqmc9c","executionInfo":{"status":"ok","timestamp":1602446531353,"user_tz":300,"elapsed":54834,"user":{"displayName":"Vishva Vipin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gin93jSJ_DOfVuwBQIXZQmHlpLnLxatAOmK-YTeiw=s64","userId":"02934471236859300555"}}},"source":["\n","from python_utils import *\n","import time\n","import matplotlib.pyplot as plt\n","import cv2 as cv\n","from math import sqrt \n","import pandas as pd\n","import numpy as np\n","from torchvision import transforms as tfs\n","import torch\n","from PIL import Image\n","from torch.autograd import Variable\n","from torchvision.utils import save_image\n","import pickle\n","import random\n","import argparse\n","import sys\n","from matplotlib import pyplot as plt\n","import matplotlib.image as mpimg\n","from matplotlib.pyplot import ion, show\n","import io\n","\n","import pandas as pd\n","import flask\n","import tensorflow as tf"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"nESamF0GmZIF","outputId":"c041b246-bce0-4d1f-a879-72e1e6aa8988","colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["\n","global graph\n","\n","graph = tf.compat.v1.get_default_graph()\n","\n","model = torch.load('fer2013_resnet18_model.pkl', map_location=torch.device('cpu'))\n","model.eval()\n","app = flask.Flask(__name__)\n","labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neural']\n","\n","def transform_image(image_bytes):\n","    image = Image.open(io.BytesIO(image_bytes))\n","    return my_transforms(image).unsqueeze(0)\n","\n","\n","def get_prediction(image_bytes):\n","    tensor = transform_image(image_bytes=image_bytes)\n","    outputs = model.forward(tensor)\n","    outputs = np.argmax(outputs.data.numpy())\n","    return outputs\n","\n","\n","@app.route(\"/\", methods=[\"GET\",\"POST\"])\n","def predict():\n","  if request.method == 'GET':\n","      return render_template('index.html')\n","\n","  if request.method == 'POST':\n","      if 'file' not in request.files:\n","          flash('No file')\n","          return redirect(request.url)\n","\n","      file = request.files['file']\n","      if file.filename == '':\n","          flash('No file')\n","          return redirect(request.url)\n","\n","      if file and allowed_file(file.filename):\n","          image = file.read()\n","\n","          class_name = get_prediction(image)\n","          return jsonify({'class_name': class_name})\n","          \n","if __name__ == '__main__':\n","  app.run(host='0.0.0.0')"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" * Serving Flask app \"__main__\" (lazy loading)\n"," * Environment: production\n","\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n","\u001b[2m   Use a production WSGI server instead.\u001b[0m\n"," * Debug mode: off\n"],"name":"stdout"},{"output_type":"stream","text":[" * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n"],"name":"stderr"}]}]}